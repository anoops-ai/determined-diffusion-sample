{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f3605-f94b-493e-be3b-fd582b83703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Demo to show case stable diffusion using determined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b25550-a078-4402-885b-7548e0da8ed5",
   "metadata": {},
   "source": [
    "## Before You Start: ðŸ¤— Account, Access Token, and License\n",
    "\n",
    "In order to use this repository's implementation of Stable Diffusion, you must:\n",
    "\n",
    "* Have a [Huggingface account](https://huggingface.co/join).\n",
    "* Have a [Huggingface User Access Token](https://huggingface.co/docs/hub/security-tokens).\n",
    "* Accept the Stable Diffusion license (click on _Access\n",
    "  repository_  [in this link)](https://huggingface.co/CompVis/stable-diffusion-v1-4).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7bc877-2c94-4b44-9414-2eac28c0332d",
   "metadata": {},
   "source": [
    "## Training Setup\n",
    "\n",
    "1. After including your user access token in the `const.yaml` config file by modifying the final part\n",
    "of the lines which read\n",
    "\n",
    "2. Update the resource pool name based on your cluster, this has been tested on 2 gpu slots of v100\n",
    "\n",
    "```yaml\n",
    "environment:\n",
    "  environment_variables:\n",
    "    - HF_AUTH_TOKEN=YOUR_HF_AUTH_TOKEN_HERE\n",
    "resources:\n",
    "  resource_pool: v100-gpu-pool #your GPU resource pool, tested against v100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7ff1f3-9ab4-4d71-a605-8f7aa8afa995",
   "metadata": {},
   "source": [
    "## Fine-tuning\n",
    "Fine-tuning experiment can be run by executing the following in the present directory\n",
    "\n",
    "The below command will submit an experiment which introduces a new embedding vector into the world of Stable\n",
    "Diffusion which we will train to correspond to the concept of the Determined AI logo, as represented\n",
    "through\n",
    "training images found in `/det_logos`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d519ac82-fd8e-4edc-8792-0446120b840c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing files (/run/determined/workdir/determined-diffusion-sample) to send to master... 3.5MB and 22 files  \n",
      "Created experiment 105\n"
     ]
    }
   ],
   "source": [
    "!det experiment create const.yaml ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185c14e4-bb89-4df1-8212-adc4c579d67c",
   "metadata": {},
   "source": [
    "By default, sample images are generated during training which can be viewed by launching a\n",
    "Tensorboard instance from the experiment in the WebUI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c4b52-ca73-4dad-849d-2f5376c1ca2f",
   "metadata": {},
   "source": [
    "## Prompt Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b2483d8-dd7e-4bf9-a1fd-53f322505393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trial ID |   # of Batches | State     | Validation Metric   | UUID                                 | Resources                  | Size\n",
      "------------+----------------+-----------+---------------------+--------------------------------------+----------------------------+---------\n",
      "        685 |            250 | COMPLETED |                     | c502af07-f1d5-4476-8809-23aa5daddda8 | learned_embeddings_dict.pt | 289.6MB\n",
      "            |                |           |                     |                                      | optimizer_state_dict.pt    |\n"
     ]
    }
   ],
   "source": [
    "# Once the fine tuning is complete, grab the UUID of best checkpoint from the above experiment. pass the experiment id from above\n",
    "!det experiment list-checkpoints --best 1 105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bb60349-fff4-4e66-8ea3-97035fea4e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries for visualization and prompt inference\n",
    "! pip install -qq jupyterlab-widgets==1.1.1 ipywidgets==7.7.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3378d83-79db-49e8-b6af-f2334d5a0c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Downloading pre-trained models...\n",
      "--------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "Building the pipeline...\n",
      "--------------------------------------------------------------------------------\n",
      "Done!\n",
      "Successfully loaded checkpoints. All loaded concepts: ['<det-logo>']\n"
     ]
    }
   ],
   "source": [
    "checkpoint_uuids = ['c502af07-f1d5-4476-8809-23aa5daddda8'] #UUID of your best ckpt from the above run\n",
    "\n",
    "# Create a textual inversion pipeline for prompt inference\n",
    "from detsd import DetSDTextualInversionPipeline\n",
    "detsd_pipeline = DetSDTextualInversionPipeline()\n",
    "\n",
    "# load ckpts\n",
    "detsd_pipeline.load_from_uuids(checkpoint_uuids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ba215c0-0a85-4dca-825a-bf1bf0c85026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory in which to save the generated images:\n",
    "!mkdir generated_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56c70fdc-0ae2-4156-a3d0-94ac383f81b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using \"<det-logo>\" as first_concept in the below\n",
      "All available concepts: ['<det-logo>']\n"
     ]
    }
   ],
   "source": [
    "# Grab the first concept which was loaded into the pipeline, if any, otherwise falling back to a default:\n",
    "try:\n",
    "    first_concept = detsd_pipeline.all_added_concepts[0]\n",
    "except IndexError:\n",
    "    first_concept = 'orange brain'\n",
    "print(f'Using \"{first_concept}\" as first_concept in the below')\n",
    "print(f'All available concepts: {detsd_pipeline.all_added_concepts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b80239-e8d7-4a1f-8267-40818129bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and inspect images based on prompt. Generating right prompts is an art\n",
    "prompt = f\"a watercolor painting on textured paper of a {first_concept} using soft strokes, pastel colors, incredible composition, masterpiece\"\n",
    "imgs = detsd_pipeline(prompt=prompt,\n",
    "                      parallelize_factor=2,\n",
    "                      rows=2,\n",
    "                      cols=2,\n",
    "                      num_inference_steps=50,\n",
    "                      seed=2147483647,\n",
    "                      guidance_scale=7.5,\n",
    "                      saved_img_dir='generated_images')\n",
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d80bee-ad8f-4586-b505-19f041f6f7c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
